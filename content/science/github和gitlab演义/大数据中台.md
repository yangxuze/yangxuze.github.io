+++

title = "大数据数据中台"

toc = true

tocNum = false

linkTitle = "大数据数据中台"
date = "2025-07-06T23:11:06+08:00"
tags = ["大数据", "数据中台",  "数仓"]
displayModifiedDate = false
align = "justify"

+++

### 大数据发展历程

整个大数据发展经历了，传统数据仓库、Hadoop 技术革命、大数据平台、数据中台这几个核心阶段。

#### 传统数仓

上世纪90年代，商业智能(BI)应运而生，将企业数据转化为知识，帮助企业进行经营决策分析。

然而，传统数据库面向单一业务系统，主要实现的是面向事务的增删改查，无法满足数据分析的大数据量范围查询需求，这促使数据仓库概念的出现。（数据库到数据仓库）

1991年，比尔·恩门(Bill Inmon)在著作《建立数据仓库》中首次完整定义了数据仓库:

```
一个面向主题的、集成的、与时间相关的、不可修改的数据集合。
```

数据仓库将不同业务系统数据按主题域组织并保留历史数据，满足分析需求。

除了数据仓库的概念，还需要知道，恩门还和金博尔（Kimball）一起开创了数仓建模的设计方法。

#### hadoop技术革命

进入互联网时代，海量异构化的数据给传统数据仓库带来了挑战，主要体现在以下两点：

* 数据规模：传统的数据仓库的存储和处理能力，已经难以应对业务发展的诉求。

* 数据类型：大量的半结构化数据（如 XML、JSON）和非结构化数据（如文本、图片、视频），传统仓库也无法处理。

2003年，谷歌发表了三篇著名的大数据论文，提出面向大数据分析的新型存储计算方法，直接奠定了现代大数据技术基础。

2005年，以谷歌的论文为基础，开源的 Hadoop 项目开始兴起，它采用完全分布式和弱化数据格式的方式，能够处理海量异构数据，满足大数据时代需求。

2010年，Pentaho 的 CTO James Dixon 提出数据湖概念，将 Hadoop 商业化，并提出将数据作为企业的核心资产。

#### 大数据平台时代

基于 Hadoop 的数据湖，逐渐出现了覆盖数据处理全流程的大数据平台。

* 计算引擎：hive、flink、spark、impala
* 资源调度管理框架：yarn
* 数据存储：hdfs、hbase

主要集成了 Hive/Spark 等计算引擎、Yarn 资源调度、HDFS/HBase 等存储系统。

大数据平台像一条流水线，通过平台将原始数据加工成指标、报表，赋能数据产品。

#### 数据中台

到了2016年，由于烟囱式开发模式，企业内部数据割裂、重复计算等问题凸显，且缺乏必要的数据治理能力，导致数据可用性和可信度很差，阻碍了数据价值的释放。

阿里率先提出"数据中台"概念，其核心是通过数据共享和数据服务化，避免数据重复计算，赋能数据应用。

数据中台架构下，企业有了统一的数据中台，通过规范的数据加工模型和标准化数据服务，各数据应用可高效共享数据，缩短开发周期、降低重复计算，数据价值得到充分释放。

### 什么是数据中台

数据中台大约是在 2018 年 5 月份左右，开始逐渐火起来的。中台这股风，之所以能火，阿里巴巴起到了非常重要的作用，中台的概念也是阿里优先提出并普及的。

所谓数据中台,顾名思义,它是以数据为核心的一种新型数据架构。

它的核心理念是通过数据的共享和服务化,来避免数据重复计算,赋能各种数据应用的创新,从而充分释放数据价值。

相较于传统的数据架构,数据中台有以下几个显著特点:

- 打破数据孤岛：实现数据资产统一管理和服务；
- 规范化数据加工模型：避免烟囱式重复开发；
- 提供统一数据服务：避免直接库表对接；
- 数据加工链路可视化,提高数据资产透明度。

### 为什么需要数据中台

在大数据时代,数据对企业的重要性不言而喻。

然而令人遗憾的是,很多企业在数字化转型的过程中,受制于传统 IT 架构的弊端,导致企业的数据价值难以体现。

主要表现在:

- **数据割裂、重复计算**

  由于采用烟囱式独立开发模式,不同系统、业务线之间的数据割裂,同一指标在不同场景下显示不一致,大量重复开发浪费资源。

- **数据价值难以体现**

  由于数据无法共享,获取成本高昂,导致数据应用缺乏创新驱动力,很难将数据价值转化为生产力。

- **应用响应效率低下**

  数据应用的迭代速度完全受制于数据开发,往往需求等待数周乃至数月才能交付,效率低下。

而数据中台则可以很好的解决以上问题。

### 数据中台价值

**通过规范化、标准化的数据中台架构,企业将获得丰富的应用价值**:

- **提高数据研发效率** 

  数据加工的规范化模型和可复用的数据服务能极大提升数据开发、分析效率,应用迭代不再受数据开发瓶颈制约。

- **实现数据资产共享** 

  数据资产得以统一管理和服务,同时避免了重复加工,最大程度复用数据,降低运营成本。

- **赋能数据产品创新** 

  通过标准化数据服务,可孵化更多创新的数据产品和应用,如商业智能、推荐系统等,助力业务创新发展。

- **支持数字化转型** 

  数据体现为企业核心资产,数据赋能业务,从根本上为数字化转型提供强有力的支撑。

### 发展趋势

随着 AI 和底层技术的不断发展，未来,数据中台仍将向**智能化、实时化、自动化**等方向发展:

- **实时数据中台** 

  采用实时计算引擎如Flink,实现批流一体,数据可以毫秒级实时获取和分析。

- **云上数据中台** 

  部署在云上,利用云计算的弹性伸缩,并与公有云数据服务融合,进一步释放数据价值。

- **智能元数据管理** 

  元数据管理智能化,主动发现数据质量问题,降低数据分析门槛。

- **自动化代码生成** 

  通过人工智能技术和可视化建模,实现自动生成数据加工代码,提高ETL研发效能。

- **数据增强分析** 

  基于知识图谱等技术,挖掘数据语义关联,为用户提供更智能的分析服务和数据产品。

### 如何建设数据中台

建设数据中台是一项系统性工程,需要从组织、技术、流程等多方面着手:

- **组织架构变革**

  需要建立独立的数据中台团队,并赋予足够的决策权和话语权,保证中台建设的权威性和执行力。

- **技术架构设计**
  需要构建统一的、标准化的数据加工链路,覆盖数据采集、存储、计算、制品输出全流程,同时实现数据的元数据管理、安全合规、服务化等一体化支撑能力。

- **流程规范制定** 

  需要制定全流程的规范化标准,包括数据模型设计规范、开发标准、测试标准、上线流程等,确保数据加工的质量。

#### 方法论

数据中台的核心建设方法论：OneData 和 OneService，是最早被提出，也是最完善的方法论。

**OneData**： 其实很好理解，就是统一数据，一次加工，避免重复造轮子；

**OneService**：则是提出统一使用数据服务 API 的方式，对上层提供服务，而不是直接开放库表权限。

这个方法论的提出者、完善者和推广者，就是阿里巴巴。

包括阿里系内部的数据中台项目，也是基于这个方法论进行构建的，比如 DataWorks 和 DataPhin。

接下来，我们分别展开讲解一下。

##### OneData

在数据仓库时期，不同的业务线或团队，都会基于自身的业务诉求，构建大大小小不同的数仓。

这其实是企业内部很常见的现象，以前，业务增长很快，有数据需求可以通过堆人的方式来解决，大量的数据被重复计算和加工，造成了大量的成本浪费。

但是，现在整个市场经济都未复苏，以前的增长神话也不复存在了，企业纷纷裁员降本。

这时候，同样的数据需求，没有那么多人力支撑，需求就无法被及时响应了。

如果恰逢重大的促销节日，市场营销部门需要基于数据制定促销计划，但是，所需数据迟迟无法提供出来，在等待数据部门排期（要一周的时间）。

对于公司而言，一周的等待时间，足以造成了巨大的损失，比如该及时促销的没有促销，不该促销的却被人为的低价售卖了。

为什么数据部门需要排期那么久？

当然是忙不过来了。

每一个业务线都有自己的小数仓，所有的数据需求都是在小数仓内加工的，即使不同的业务线使用了同样的数据，依然要被多次在不同的小数仓中重复加工。

那么，为什么内部的数据不能复用？为什么要重头再计算一遍呢？

因为不同的小数仓是不同的人负责的，一方面企业内部存在严重的信息茧；另一方面，没有多少人愿意与别人协同，或者求别人提供帮助。

最终的行动就变成了：自己动手搞一个中间表自己用。

而 OneData 方法论就是在横跨不同的业务线，加工一个公共数据层，消灭这些跨部门的小数仓，实现数据的统一复用。

这样说可能还是比较模糊，那么，我们如何实现 OneData 呢？

如果想要实现 OneData，核心要做到统一规范和统一建设。

细化一下就是：

- 数仓分层
- 构建主题域
- 制定表命名规范

企业内部少则几百张表，多则上万张表，同时，又是由数十个开发同学负责开发和维护这些表的，甚至还有一些外包同学在负责。

该如何管理这些表，提高管理效率，以及如何实现数据复用呢?

那么，最好的方式就是结合传统数仓分层理念，对数据模型进行分层管理，常见的分层包括：ODS层-原始数据层，DWD层-明细数据层，DWS层-轻度汇聚层，ADS层- 应用数据层。

以及基于业务特征将不同的表划分到不同的主题域中，比如零售行业，就会存在商品域、交易域、供应链域、用户域等主题域。

除此之外，还需要对表的命名进行规范化管理，业内的最佳实践是在表名上包含分层、主题域、业务过程、更新策略等信息。

比如供应链主题域下的一张表，每日增量更新，则可以命名为：dwd_supplychain_sales_order_di。

有人可能有疑问了：这些东西传统数仓就可以做到啊？为什么一定要数据中台

好问题，其实，这些在传统的数据仓库中，也会使用，差别点在于有没有严格按照 OneData 的理念去落地。

##### OneService

数据中台强调通过数据服务的方式对外提供数据服务，而不是像传统数仓那样，直接暴露出库表信息给下游，让下游直接消费数据来使用。

那么，为什么要使用数据服务来提供服务？

试想一下，企业现在有 1000多张表，年底了，需要盘点每个人名下有哪些表不用了，需要做下线处理。

其中，你名下有 100 多张表，请问你如何判断有哪些表需要下线？

传统直接对接库表的方式，缺少必要的身份认证及使用监控，这就导致很难直观的判断表被哪些应用在使用？是否还在使用？使用频率是怎样的？下线了影响如何？

而，数据服务通过 API 的方式对下游提供数据服务，不仅仅可以屏蔽底层的数据源对接复杂度，而且能够监控到下游应用的使用情况，包含调用频率，调用是否成功等。

针对调用异常的情况，还可以通过详细的调用日志来排查。

总之，OneService 可以提高数据的共享效率，同时，大大的提高数据管理的效率。

除了方法论以外，还需要底层的技术支持和组织支持，才能更好的完成数据中台的建设工作。

就像建设一栋房子，需要设计图纸、各类建筑工具还有各类工种成员，方法论就像是设计图纸，但是，只有设计图纸是远远不够的。

还需要建筑工具和建筑工人配合，而技术就像各类建筑工具，建筑工人就像组织内部的员工。

#### 数据中台支撑技术

在数据管理方面，除了方法论外，工具是另外一个必不可少东西，它可以让你的数据中台建设事半功倍。

数据中台的支撑技术，核心是基于 Hadoop 体系的各类组件，包含存储和计算等。

核心是以HDFS为代表的分布式文件系统，以 Yarn 为代表的资源调度系统，以及，以 Hive、Impala、Presto、Flink 为代表的计算引擎，都属于技术设施。

这些都是数据中台的地基，也是大数据技术平台的核心组件。

**而数据中台和大数据技术平台的最大差异，就是在大数据技术的基础上，基于 OneData、OneService方法论，实现数据统一标准，统一加工，统一治理及统一服务。**

#### 组织架构

企业内部会有很多小数仓，分布在不同的业务线里面，最终形成了一个个数据孤岛。

导致这种现象的根本就是因为，每个业务线都养着一个数仓团队，来专门服务对应的业务线。

因此，构建数据中台的一个核心动作就是，要有一个独立的中台团队来负责企业内部的数据。

主要职责就是：

- 构建中台
- 建设企业公共数据层
- 牵头制定企业数据标准
- 牵头制定企业数据质量规则
- 构建企业数据服务
- 构建数据应用

而这个部门一定要有一定的话语权，且直接向企业管理层汇报工作。

作为独立支撑部门，最大的风险就是离业务太远，容易闭门造车，所以，部门的人员一定要懂业务，能够深入业务。

为了确保这一点，在绩效目标设计上，就需要将中台组织的绩效目标和业务落地价值绑定。

最后，数据中台的组织架构改革涉及原有各个部门的利益，所以这个是数据中台构建最难又不得不做的地方，必须要取得高层领导的支持和重视。

### 数据中台各个模块

#### 元数据

元数据从分类上来说，会分为技术元数据、业务元数据和管理元数据。这三类元数据，只是分类，那么，元数据应该包含哪些信息呢？

会有这么几种信息：**基础特征信息、血缘信息、动态特征信息。**

以表资产来举例：

| 信息         | 说明                                      |
| ------------ | ----------------------------------------- |
| 基础特征信息 | 比如表名、注释信息、字段信息、字段类型等  |
| 血缘信息     | 表的上下游表，以及对应的加工过程任务/作业 |
| 动态特征信息 | 主要是表质量校验信息、热度和查询记录等    |

以上信息就是表的元数据信息，通过这个例子，你对元数据有一定的了解了吗？

如果还是有些疑问，你也可以把元数据理解成书本的目录，在目录页记录了书本的段落，段落所在的页码，以及对应段落的核心要点信息。

这些都可以帮助你更好的了解书本内容，也可以帮助你快速的定位到所需的章节。

元数据虽然是描述数据的数据，本质上还是数据，仍然存在物理形态。

这就涉及到数据从哪里来？如何存储？如何管理?

因此，元数据中心需要包含：

- 元数据采集服务
- 消息中间件
- 元数据存储
- 元数据消费/查询服务

除此之外，还有一些企业，会额外设计关于血缘清理的模块，不过这个不是必须的，可以根据企业自身情况而定。

***\*元数据从哪里来\****

从不同的数据来源采集过来的。

不管是 Hive、Spark、Flink，还是数据湖格式，比如 Hudi 等，都可以通过元数采集服务来采集他们的元数据。

市面上有一些开源的元数据服务产品，比如奈飞开源的 MetaCat、或者 Apache Atlas，他们已经支持很多类型的数据源，并且他们的采集器也是采用可拓展的开放式架构。

企业可以借鉴他们的设计思路，或者在他们开源的源代码基础上去拓展支持所需的数据源。（这里我个人是支持将支持的数据源再贡献给社区去，具体根据企业情况酌情处理吧，我国这块一直做得不太好 ，虽然一直在改善）。

***\*血缘信息如何采集\****

血缘关系获取一般有三种方式：

- 通过静态解析 SQL；
- 通过实时抓取正在执行的 SQL，解析执行计划；
- 通过任务日志解析的方式。



第一种方式，面临准确性的问题，因为任务没有执行，这个 SQL 对不对都是一个问题。

第三种方式，血缘虽然是执行后产生的，可以确保是准确的，但是时效性比较差，通常要分析大量的任务日志数据，如果对血缘实时性要求比较高的话，这个方案也不太适合。

我个人更看好第二种方式，既保障了实时性，又保障了准确性，而 Atlas 就是采用了这种实现。

**元数据长什么样**

说了很多关于元数据的底层构成及技术点，那么它到底长什么样子？

用户如何使用这个元数据中心呢？

其实，元数据中心最核心的服务形式是 API，而不是页面。不管是对接 IDE、数据服务还是数据治理，都是通过 API 来和其他模块交互的，元数据通过 API 提供元数据的查询服务。

但是，有一个产品几乎完全基于元数据中心构建的，那就是数据中台中的数据地图模块。

 **数据地图**

数据地图顾名思义是帮助用户便捷找到并理解数据的模块，主要面向数据开发、数据分析师、业务分析师、算法工程师等角色。

数据地图提供了多维度检索数据的功能，用户可以通过检索表名、表注释、字段、字段注释、标签、数据分层等信息检索所需的数据。

除了便捷的找到所需的数据外，数据地图还支持查看对应数据的详细元数据信息，比如表数据，检索到所需的表后，可以在数据地图中查看到表的注释信息、字段信息（包含字段注释、字段类型等）、表血缘信息（包含表的加工任务信息）、以及表的分区信息等。

总之，让你快速了解这个表的来龙去脉。

如果以上信息还不够的话，你还可以通过数据预览功能，查看表的样例数据，用于判断数据是否符合使用者的预期。不过为了数据安全，一般会控制预览的条数，一些安全要求比较高的企业，甚至会限制用户可以预览的字段。

综上所述，数据地图虽然不是元数据中心，但是，核心信息都是来源于元数据中心，也是用户使用最高频的一个数据中台模块。

***\*有没有开源的元数据产品\****

元数据管理产品有很多开源的，比较出名的有：

- 奈飞的 Metacat
- Linkdin DataHub
- Apache Atlas

Metacat主要用于科学数据管理，DataHub用于协作数据集的管理，而Atlas则是用于企业数据湖和数据资产管理。

企业该如何选型呢？

其实，每款产品都有其发展路线，所以也有会不同的适用场景。
Metacat 更轻量，具有良好的元数据版本管理能力，便于内部数据共享和发现。

DataHub 则专注于数据集的协同管理，在团队协作方面做得更出色，开源社区也非常活跃。

而 Atlas 具有完善的数据治理和安全管控能力，更适合企业级组织，在大规模数据资产管理方面更有优势，相应的其结构也会更加复杂，使用和维护成本更高。

**数据血缘**

数据血缘是表达数据来龙去脉及数据间关系的能力，它在数据影响力分析，和故障问题追踪定位方面有着非常重要的作用。

比如，我们需要对业务系统数据库的某个表做字段类型变更，这时候我们就可以借助数据血缘，查看改动对下游哪些任务/表/指标有影响，可以找到对应负责人提前沟通，避免直接改动引发线上事故。

再比如，你负责的某个指标数据出现了较大波动，意识到数据不太正常，你可以借助血缘关系视图，找到上游的表或任务，了解他们是否发生了变动或出现了故障，可以快速的定位到故障点。

由此可见，数据血缘在数据资产维护和团队协同方面起到了巨大的作用。

但是，构建数据血缘并不是一件简单的事情，据我所知，很多知名的大厂，在这块的产品构建也非常的落后，数据血缘不完整、不及时、不准确的事情时常发生。

 **01 数据血缘为什么那么难搞**

通常情况下，有以下几种方式获得数据血缘：

1. 通过解析 SQL
2. 通过 API 或者消息通道
3. 通过系统对接
4. 人工维护
5. 通过导入 ER 图代码

上面虽然列举了常见的 5 种获取血缘的途径，但是，以上方式没有任何一种可以完成企业内部 100% 的数据血缘维护，通常是几个方式组合使用才可以。

这也是为什么，市面上迟迟没有一款全自动化的数据血缘维护工具的原因，不管是开源还是商业化产品。

当然，每一种方案也有其落地的难度，比如第 1 种，通过解析 SQL 的方式获取血缘，就有以下 3 种方案。

- 通过静态解析 SQL；
- 通过实时抓取正在执行的 SQL，解析执行计划；
- 通过任务日志解析的方式。

第一种方式，面临准确性的问题，因为任务没有执行，这个 SQL 对不对都是一个问题。

第三种方式，血缘虽然是执行后产生的，可以确保是准确的，但是时效性比较差，通常要分析大量的任务日志数据，如果对血缘实时性要求比较高的话，这个方案也不太适合。

我个人更看好第二种方式，既保障了实时性，又保障了准确性，而 Atlas 就是采用了这种实现。

你看，随便一种方案，都存在一定的难度，更重要的事，解析准确率一般最多只能做到 95%左右，针对特定引擎比如 Hive有可能做到 98%。

额外，由于企业内部使用了多种数据库和计算引擎，这也加大了很多难度和工作量。

看吧，数据血缘并没有想想的那么简单。

这还是单个系统上的难度，如果企业想要实现全链路的数据血缘关系，那将更加的困难，比如想要看到业务系统的表、经过数据仓库/大数据平台/数据中台、数据服务、指标平台、BI 可视化平台等全链路的血缘视图。

很重要的一个原因是：企业不同的数据系统是由不同的供应商支撑的，而多数系统的数据血缘是内部血缘，且缺少对外开放的接口，导致全链路血缘这件事情几乎没法落地。

**02 有什么开源的产品推荐**

数据血缘的管理和可视化展示，有很多的开源产品，比如：

| 产品           | 活跃度                                                       | 评估         |
| -------------- | ------------------------------------------------------------ | ------------ |
| Apache Lineage | GitHub stars：1,800+，GitHub forks：400+，每月贡献者：10+    | 活跃社区     |
| DataHub        | GitHub stars：12,000+，GitHub forks：2,000+，每月贡献者：50+ | 非常活跃社区 |
| Amundsen       | GitHub stars：8,000+，GitHub forks：1,500+，每月贡献者：30+  | 非常活跃社区 |
| Atlas          | GitHub stars：4,000+，GitHub forks：800+，每月贡献者：20+    | 活跃社区     |

**我个人更看好 DataHub 和 Amundsen 这两款产品。**

**DataHub** 拥有最大的社区和最全面的功能集，包括数据血缘、数据治理和数据质量管理等功能。

它适用于需要一个一体化平台来管理其所有数据资产的大型企业。

**Amundsen** 是一款以数据发现为重点的工具，它可以帮助您轻松找到和理解您的数据。它适用于需要一种简单方法来探索其数据的组织。

其他工具也各有优劣：

- **Apache Lineage** 是一款轻量级工具，非常适合小型团队或想要快速入门数据血缘的组织。
- **Atlas** 是一款功能强大的工具，但可能需要更多的设置和维护。

最终选择哪款工具取决于您的具体需求和要求。

#### 数据集成

#### 数据开发

#### 数据运维

#### 数据质量

https://mp.weixin.qq.com/s/jEoYyvD1bNuuCM7yRQfltA

#### 数据安全

#### 数据服务





> 参考“唐晨说数”，当前看到2024.05.13 很多人没搞懂数据质量 https://mp.weixin.qq.com/s/jEoYyvD1bNuuCM7yRQfltA